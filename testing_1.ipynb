{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'selenium-twitter-scraper/scraper', '--tweets=10', '--username=PikaMoonCoin'], returncode=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess \n",
    "\n",
    "username = 'PikaMoonCoin'\n",
    "subprocess.run([\"python\", \"selenium-twitter-scraper/scraper\", \"--tweets=10\", f\"--username={username}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anush\\AppData\\Local\\Temp\\ipykernel_13440\\1455726177.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  tweets.append(row[4])\n",
      "C:\\Users\\anush\\AppData\\Local\\Temp\\ipykernel_13440\\1455726177.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  hashtags.append(ast.literal_eval(row[9]))\n",
      "C:\\Users\\anush\\AppData\\Local\\Temp\\ipykernel_13440\\1455726177.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  dates.append(row[2][:10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2024-04-19',\n",
       " '2024-07-15',\n",
       " '2024-07-15',\n",
       " '2024-07-15',\n",
       " '2024-07-14',\n",
       " '2024-07-12',\n",
       " '2024-07-11',\n",
       " '2024-07-10',\n",
       " '2024-07-09',\n",
       " '2024-07-08']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import ast\n",
    "\n",
    "now = datetime.now()\n",
    "formatted_now = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "formatted_now = '2024-07-16_12-19-11'\n",
    "df = pd.read_csv(f\"tweets/{formatted_now}_tweets_1-10.csv\")\n",
    "tweets, hashtags, dates = [], [], []\n",
    "for i, row in df.iterrows():\n",
    "    tweets.append(row[4])\n",
    "    hashtags.append(ast.literal_eval(row[9]))\n",
    "    dates.append(row[2][:10])\n",
    "dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#Pikamoon']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "total_lists = len(hashtags)\n",
    "half_lists = total_lists // 4\n",
    "hashtag_counts = Counter()\n",
    "for hashtags_l in hashtags:\n",
    "    unique_hashtags = set(hashtags_l)\n",
    "    hashtag_counts.update(unique_hashtags)\n",
    "frequent_hashtags = [hashtag for hashtag, count in hashtag_counts.items() if count >= half_lists]\n",
    "frequent_hashtags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m frequent_hashtags:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241m.\u001b[39mrun([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselenium-twitter-scraper/scraper\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--tweets=10\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--hashtag=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      3\u001b[0m     now \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m      4\u001b[0m     formatted_now \u001b[38;5;241m=\u001b[39m now\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'subprocess' is not defined"
     ]
    }
   ],
   "source": [
    "for tag in frequent_hashtags:\n",
    "    subprocess.run([\"python\", \"selenium-twitter-scraper/scraper\", \"--tweets=10\", f\"--hashtag={tag[1:]}\"])\n",
    "    now = datetime.now()\n",
    "    formatted_now = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    formatted_now = '2024-07-16_12-19-11'\n",
    "    df = pd.read_csv(f\"tweets/{formatted_now}_tweets_1-10.csv\")\n",
    "    for i, row in df.iterrows():\n",
    "        tweets.append(row[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Pikamoon: Openworld Trailer (Teaser) $PIKA is a movement.\n",
      "\n",
      "The #PIKAARMY march together everyday.\n",
      "\n",
      "Our game will be AAA \n",
      "---------\n",
      "Team Meal at Orbit Cosmos Tonight  \n",
      "\n",
      "Let’s eat up and keep fuelling  \n",
      "---------\n",
      "Good morning, #Pikamoon community!\n",
      "\n",
      "We're all at our development office in Pakistan!Monday Giveaway ($250 of $PIKA) \n",
      "\n",
      "To participate:Follow   \n",
      "---------\n",
      "We're also filming a behind-the-scenes documentary of this trip to further demonstrate our transparency and dedication to the future.\n",
      "\n",
      "Stay tuned, PIKA Army!\n",
      "---------\n",
      "Here's another sneak peek of the #Pikamoon Open World!\n",
      "\n",
      "We're making tremendous progress every week \n",
      "---------\n",
      "Keep bringing us that $PIKA stuff \n",
      "---------\n",
      "GM from  \n",
      "\n",
      "Meet some of the team:Muhammad Umair (3D Modeler) Hamza Siddiqui (CG Generalist) Salik Saeed (Animator)Jazib Tasaduq (Managing Director)$100 GIVEAWAY\n",
      "---------\n",
      "We're excited to share a very early version of the #PIKAMOON open world with you!\n",
      "\n",
      "Please note, this post is solely to showcase our development progress Rest assured, the quality will improve even further before the first public release Stay tuned for more updates!\n",
      "---------\n",
      "Pikamoon began as a mere idea back in October 2022…\n",
      "\n",
      "Three friends, Brock, Kanto, and Nix, sat envisioning how to revolutionise the P2E gaming world. \n",
      "\n",
      "The bull market was behind us, nothing (literally nothing!) was happening, yet Pikamoon has since blossomed into what we see\n",
      "---------\n",
      "#Pikamoon Character Reveal The NOMAD \n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "raw_tweets = 'Here are the last few posts from a crypto token & its followers:\\n'\n",
    "for i in tweets:\n",
    "    print(i)\n",
    "    raw_posts = raw_posts + i +\"\\n-\\n\"\n",
    "    print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anush\\OneDrive\\Desktop\\Work\\smallcap\\scraper-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'Neutral', 'score': 0.6220372915267944},\n",
       " {'label': 'Bullish', 'score': 0.9156750440597534},\n",
       " {'label': 'Neutral', 'score': 0.5735231041908264},\n",
       " {'label': 'Bullish', 'score': 0.5215172171592712},\n",
       " {'label': 'Neutral', 'score': 0.7277060151100159},\n",
       " {'label': 'Bullish', 'score': 0.9500432014465332},\n",
       " {'label': 'Neutral', 'score': 0.7635330557823181},\n",
       " {'label': 'Neutral', 'score': 0.5506970286369324},\n",
       " {'label': 'Bullish', 'score': 0.936409592628479},\n",
       " {'label': 'Neutral', 'score': 0.6510459780693054}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TextClassificationPipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "model_name = \"AfterRain007/cryptobertRefined\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = 3)\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, max_length=128, truncation=True, padding = 'max_length')\n",
    "preds = pipe(tweets)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Team Meal at Orbit Cosmos Tonight  \\n\\nLet’s eat up and keep fuelling  ',\n",
       " 'Keep bringing us that $PIKA stuff ',\n",
       " 'Pikamoon began as a mere idea back in October 2022…\\n\\nThree friends, Brock, Kanto, and Nix, sat envisioning how to revolutionise the P2E gaming world. \\n\\nThe bull market was behind us, nothing (literally nothing!) was happening, yet Pikamoon has since blossomed into what we see']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tweets = []\n",
    "for i in range (len(tweets)):\n",
    "    if preds[i]['score'] > 0.7 and preds[i]['label'] in ['Bearish', 'Bullish']:\n",
    "        filtered_tweets.append(tweets[i])\n",
    "filtered_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The 10 most recent tweets from the given user ranges between 2024-04-19 to 2024-07-08, which gives an average posts per month rate of 3.75'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "first = datetime.strptime(dates[0], \"%Y-%m-%d\")\n",
    "last = datetime.strptime(dates[9], \"%Y-%m-%d\")\n",
    "diff_d = abs((first-last).days)\n",
    "rate_d = len(dates) / diff_d if diff_d > 0 else len(dates)\n",
    "\n",
    "post_rate = f'''The 10 most recent tweets from the given user ranges between {dates[0]} to {dates[9]}, which gives\n",
    "an average posts per month rate of {rate_d*30}. '''.replace('\\n', ' ')\n",
    "post_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Out of the posts collected, our sentiment analysis model found 40%  of the posts to be positive, and 0% negative. '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count occurrences of 'bearish' and 'bullish'\n",
    "bearish_count = sum(1 for item in preds if item['label'] == 'Bearish')\n",
    "bullish_count = sum(1 for item in preds if item['label'] == 'Bullish')\n",
    "sent_perc = f'''Out of the posts collected, our sentiment analysis model found {int(bullish_count/len(tweets)*100)}% \n",
    "of the posts to be positive, and {int(bearish_count/len(tweets)*100)}% negative. '''.replace('\\n', ' ')\n",
    "sent_perc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17788\n"
     ]
    }
   ],
   "source": [
    "import json, os, requests\n",
    "from urllib.request import urlopen\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "cname = 'pikamoonofficial'\n",
    "url = f\"https://api.telegram.org/bot{os.environ.get('token1')}:{os.environ.get('token2')}/getChatMemberCount?chat_id=@pikamoonofficial\"\n",
    "with urlopen(url) as f:\n",
    "    resp = json.load(f)\n",
    "\n",
    "print(resp['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "---------------------------\n",
      "---------------------------\n",
      "---------------------------\n",
      "---------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here are the last few posts from a crypto token:\\nAnother Sneak Peak 👀\\n\\nhttps://x.com/pikamooncoin/status/1814899154268688692?s=46\\n-\\nhttps://x.com/pikamooncoin/status/1814174297356980706?s=46\\n-\\nTeam Meal \\n\\nhttps://x.com/orbitcosmosvc/status/1812879236098920786?s=46\\n-\\nHello From Pakistan 🇵🇰 \\n\\nhttps://x.com/pikamooncoin/status/1812743500011864486?s=46\\n-\\nHead over to our X for the latest Open World update 😁\\n\\n@ pikamooncoin 💎\\n-\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# Load the JSON data from the file\n",
    "with open('channel_messages.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "# Loop over the JSON object content\n",
    "raw_posts = 'Here are the last few posts from a crypto token:\\n'\n",
    "for entry in data[:5]:\n",
    "    # Print the desired values\n",
    "    # print(f\"Date: {entry['date']}\")\n",
    "    # print(f\"Message: {entry['message']}\")\n",
    "    # print(f\"Desc: {entry['description']}\")\n",
    "    # print(\"---------------------------\")\n",
    "    raw_posts = raw_posts + entry['message'].strip()+\"\\n-\\n\"\n",
    "raw_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anush\\OneDrive\\Desktop\\Work\\smallcap\\scraper-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head over to our X for the latest Open World update. Here are the last few posts from a crypto token: Another Sneak Peak, Hello From Pakistan and Team Meal.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "result = summarizer(raw_posts, max_length=130, min_length=30, do_sample=False)\n",
    "print(result[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
